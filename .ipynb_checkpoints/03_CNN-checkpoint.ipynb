{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   # Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will put together a CNN using Keras. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports for building models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports for data pre-processing and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "#https://github.com/jrosebr1/imutils\n",
    "from keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LetNet architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start we will use a simple image classifier architecture called LetNet.\n",
    "\n",
    "Layers:\n",
    "\n",
    "Input -> Convolution_1 -> Pooling_1 -> Convolution_2 -> Pooling_2 -> Fully_Connected_Hidden_Layer -> Output_Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up LeNet CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a class for the model\n",
    "class LeNet:\n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes):\n",
    "        #Create instance of model\n",
    "        model = Sequential()\n",
    "        inputShape = (height, width, depth)\n",
    "        #Add layers\n",
    "        \n",
    "        #First convolutional layer w/ 20 convolutional filters which are 5x5 pixels\n",
    "        #Padding set to same so input size into the convolution is the same as output\n",
    "        #Activation can be set in convolutiuonal layer or added separately\n",
    "        model.add(Conv2D(filters=20, kernel_size=5, padding='same',\n",
    "                         input_shape=inputShape, activation='relu'))\n",
    "        #model.add(Activation('relu'))\n",
    "        #Calculate the max values of pixels in a window size of 2x2 pixels\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "        #2nd covolutional layer\n",
    "        model.add(Conv2D(filters=50, kernel_size=5, padding='same',\n",
    "                        activation='relu'))\n",
    "        model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "        #Flatten layer serves as a connecter between convolution and densely connected layers\n",
    "        #Flattens into a single vector\n",
    "        model.add(Flatten())\n",
    "        #Dense layer contains 500 fully connected nodes\n",
    "        model.add(Dense(500, activation='relu'))\n",
    "        #Can add activation layer separately\n",
    "        #model.add(Activation('relu'))\n",
    "        #Output will be number of classes, softmax will yield probability of each class\n",
    "        model.add(Dense(classes, activation='softmax'))\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#containers for pre-processed image data and class labels\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "#images directory contains 3 sub-directories: 'poison_ivy', 'poison_oak', 'poison_sumac'\n",
    "#randomly get image paths and shuffle them\n",
    "image_paths = sorted(list(paths.list_images('C:\\\\Users\\\\jltsa\\\\Desktop\\\\Project_2\\\\test_images')))\n",
    "random.seed(42)\n",
    "random.shuffle(image_paths)\n",
    "\n",
    "#preprocess images to 28x28 pixels as required for LeNet\n",
    "for image_path in image_paths:\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (28, 28))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "    \n",
    "    #Extract class labels\n",
    "    label = image_path.split(os.path.sep)[-2]\n",
    "    if label == 'poison_ivy':\n",
    "        label = 0\n",
    "    elif label == 'poison_oak':\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 2\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling Images\n",
    "\n",
    "#Scal pixel intensities from 0 to 1\n",
    "data = np.array(data, dtype='float') / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize global training variables\n",
    "\n",
    "EPOCHS = 25\n",
    "#Learning rate\n",
    "LR = 1e-3\n",
    "#Batch Size\n",
    "BS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One hot encoding\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To increase the amount of training data, build an image generator using data augmentation\n",
    "aug_gen = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "                            height_shift_range=0.1, shear_range=0.2,\n",
    "                            zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model\n",
    "model = LeNet.build(width=28, height=28, depth=3, classes=3)\n",
    "opt = Adam(lr=LR, decay=LR / EPOCHS)\n",
    "\n",
    "#if model has 2 classes use loss='binary_crossentropy'\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt,\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "27/27 [==============================] - 8s 292ms/step - loss: 1.1382 - acc: 0.3222 - val_loss: 1.1028 - val_acc: 0.5000\n",
      "Epoch 2/25\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 1.0593 - acc: 0.4549 - val_loss: 1.2570 - val_acc: 0.4000\n",
      "Epoch 3/25\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.9984 - acc: 0.4973 - val_loss: 1.2703 - val_acc: 0.3000\n",
      "Epoch 4/25\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.8754 - acc: 0.5848 - val_loss: 1.2990 - val_acc: 0.4000\n",
      "Epoch 5/25\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.7562 - acc: 0.6538 - val_loss: 1.5162 - val_acc: 0.3000\n",
      "Epoch 6/25\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.6731 - acc: 0.7042 - val_loss: 1.7903 - val_acc: 0.4000\n",
      "Epoch 7/25\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.6626 - acc: 0.7196 - val_loss: 1.9283 - val_acc: 0.4000\n",
      "Epoch 8/25\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.4961 - acc: 0.7905 - val_loss: 1.8668 - val_acc: 0.3000\n",
      "Epoch 9/25\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.4965 - acc: 0.8203 - val_loss: 2.4622 - val_acc: 0.4000\n",
      "Epoch 10/25\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 0.4269 - acc: 0.8276 - val_loss: 2.5116 - val_acc: 0.4000\n",
      "Epoch 11/25\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.3030 - acc: 0.9123 - val_loss: 2.6266 - val_acc: 0.5000\n",
      "Epoch 12/25\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.2877 - acc: 0.9090 - val_loss: 2.1842 - val_acc: 0.4000\n",
      "Epoch 13/25\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1377 - acc: 0.9653 - val_loss: 2.5969 - val_acc: 0.4000\n",
      "Epoch 14/25\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.1872 - acc: 0.9293 - val_loss: 3.4352 - val_acc: 0.5000\n",
      "Epoch 15/25\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.9167 - acc: 0.7086 - val_loss: 1.9706 - val_acc: 0.2000\n",
      "Epoch 16/25\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.4369 - acc: 0.8215 - val_loss: 2.5628 - val_acc: 0.4000\n",
      "Epoch 17/25\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1330 - acc: 0.9573 - val_loss: 2.8185 - val_acc: 0.5000\n",
      "Epoch 18/25\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.2308 - acc: 0.9243 - val_loss: 2.5521 - val_acc: 0.5000\n",
      "Epoch 19/25\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.1085 - acc: 0.9711 - val_loss: 2.3114 - val_acc: 0.6000\n",
      "Epoch 20/25\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0942 - acc: 0.9637 - val_loss: 2.8186 - val_acc: 0.5000\n",
      "Epoch 21/25\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0502 - acc: 0.9893 - val_loss: 3.2126 - val_acc: 0.5000\n",
      "Epoch 22/25\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0356 - acc: 0.9939 - val_loss: 3.7895 - val_acc: 0.5000\n",
      "Epoch 23/25\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0248 - acc: 0.9970 - val_loss: 3.5293 - val_acc: 0.5000\n",
      "Epoch 24/25\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 0.0458 - acc: 0.9939 - val_loss: 3.8037 - val_acc: 0.5000\n",
      "Epoch 25/25\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 0.0303 - acc: 0.9939 - val_loss: 3.6397 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x249f191bc88>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train model\n",
    "model.fit_generator(aug_gen.flow(X_train, y_train, batch_size=BS),\n",
    "                   validation_data=(X_test, y_test), steps_per_epoch=len(X_train // BS),\n",
    "                   epochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "model.save('poison_plant_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "#model = load_model('poison_plant_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
